<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Etowah Adams</title><link>https://etowahadams.github.io/</link><description>Recent content on Etowah Adams</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Tue, 16 Jul 2024 08:19:07 -0500</lastBuildDate><atom:link href="https://etowahadams.github.io/index.xml" rel="self" type="application/rss+xml"/><item><title>Molecular cloning, or why some biologists become superstitious</title><link>https://etowahadams.github.io/post/2024-07-17-cloning/</link><pubDate>Tue, 16 Jul 2024 08:19:07 -0500</pubDate><guid>https://etowahadams.github.io/post/2024-07-17-cloning/</guid><description>
&lt;p>Molecular cloning: it is a ubiquitous and essential molecular biology technique, yet it’s the bane of many a scientist&amp;rsquo;s existence. If you&amp;rsquo;ve ever overheard a biologist muttering curses at a petri dish, chances are their cloning has gone wrong.&lt;/p>
&lt;figure>
&lt;a data-fancybox="" href="meme.png" data-caption="A common cloning experience">
&lt;img src="meme.png" data-src="meme.png" class="lazyload" alt="" >&lt;/a>
&lt;figcaption style="text-align:left">
A common cloning experience
&lt;/figcaption>
&lt;/figure>
&lt;p>Don&amp;rsquo;t believe me? Let&amp;rsquo;s take a peek at the &lt;a href="https://www.reddit.com/r/labrats/">r/labrats&lt;/a> subreddit, where desperate researchers bare their souls:&lt;/p>
&lt;ul>
&lt;li>
&lt;p>“&lt;a href="https://www.reddit.com/r/labrats/comments/15sow73/comment/jwfj80q/?utm_source=share&amp;amp;utm_medium=web2x&amp;amp;context=3">For cloning, the most reliable method is a contract with a demon, higher the better.”&lt;/a>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&amp;ldquo;&lt;a href="https://www.reddit.com/r/labrats/comments/11hwtol/i_just_feel_defeated/">But of course the gods of cloning have different ideas about my free time. None of the reactions, even the control one, succeed.&lt;/a>”&lt;/p>
&lt;/li>
&lt;li>
&lt;p>“&lt;a href="https://www.reddit.com/r/labrats/comments/pclq17/comment/hajvgst/?utm_source=share&amp;amp;utm_medium=web3x&amp;amp;utm_name=web3xcss&amp;amp;utm_term=1&amp;amp;utm_content=share_button">Cloning, like most of molecular biology is black magic. I&amp;rsquo;ve never met more superstitious people then molecular biologists, and seemingly the more superstitious the better they were in the lab.&lt;/a>”&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>Nothing says &amp;ldquo;doing science&amp;rdquo; quite like demonic bargaining, right?&lt;/p>
&lt;p>Even when you think you’ve emerged triumphant from your cloning, there’s a good chance you haven’t. In a recent analysis of 2,521 plasmids constructed by researchers and sent to molecular cloning company VectorBuilder, &lt;a href="https://www.biorxiv.org/content/10.1101/2024.06.17.596931v1">nearly half contained errors&lt;/a> compared to the reference sequence. Abysmal. (if you’re reading this and know of other interesting cloning related studies, let me know!)&lt;/p>
&lt;p>To be fair, cloning isn’t the only dark art in molecular biology. One study finds human-designed &lt;a href="https://www.biorxiv.org/content/10.1101/2021.08.12.455589v1.full">PCR fails 37-45% of the time&lt;/a>. A study investigating how well 2165 recombinant human proteins express in hamster cells found that &lt;a href="https://www.biorxiv.org/content/10.1101/2022.12.12.520152v1?s=09">41% of human proteins did not have detectable expression&lt;/a>. Perhaps I will think more extensively about these other methods in the future. But I suspect learning from cloning will provide insight into these others too.&lt;/p>
&lt;p>Why does cloning make biologists contemplate career changes? And does it have to be this way?&lt;/p>
&lt;h2 id="cloning-101">
&lt;a href="#cloning-101" class="anchor">
&lt;svg class="icon" aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16">
&lt;path fill-rule="evenodd"
d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z">
&lt;/path>
&lt;/svg>
&lt;/a>
Cloning 101
&lt;/h2>
&lt;p>First, a little background. Molecular cloning is the process of assembling pieces of DNA into a circle (a plasmid) that can replicate inside a host organism. It&amp;rsquo;s the first step in many critical tasks, from protein production to gene editing. The process looks like this:.&lt;/p>
&lt;ol>
&lt;li>Design your plasmid&lt;/li>
&lt;li>Assemble DNA fragments&lt;/li>
&lt;li>Transform host cells with the assembled DNA&lt;/li>
&lt;li>Identify clonal colonies with the correctly assembled plasmid&lt;/li>
&lt;/ol>
&lt;p>End to end, this process should take just a few days. Emphasis on should.&lt;/p>
&lt;h2 id="plagued-by-uninformative-latent-failure">
&lt;a href="#plagued-by-uninformative-latent-failure" class="anchor">
&lt;svg class="icon" aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16">
&lt;path fill-rule="evenodd"
d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z">
&lt;/path>
&lt;/svg>
&lt;/a>
Plagued by uninformative latent failure
&lt;/h2>
&lt;p>Unfortunately, cloning outcomes can be quite variable, even for experienced practitioners. Sometimes it works flawlessly on the first try, leaving you feeling like a real scientist. Other times, it works once but refuses to cooperate ever again. And then there are those dark times when it stubbornly fails, again and again for weeks, leaving you with no choice but to sacrifice your first-born child. Wait, are we still talking about cloning?&lt;/p>
&lt;p>When cloning fails, it&amp;rsquo;s not very forthcoming about why. There are only a few observable failure states:&lt;/p>
&lt;ol>
&lt;li>Cells with incorrect plasmids (misassembled, mutated, or containing part/backbone plasmids)&lt;/li>
&lt;li>No cells growing at all&lt;/li>
&lt;/ol>
&lt;p>That&amp;rsquo;s all the feedback you get. Each failure could be the result of any number of different errors. I call this uninformative failure.&lt;/p>
&lt;p>Another thing to notice is that failure is observed far after a potential error is made. This is called latent failure. You have to carry out the whole process to see if you did something wrong, making debugging cycles take forever.&lt;/p>
&lt;figure>
&lt;a data-fancybox="" href="fig1.png" data-caption="Latent failure of cloning">
&lt;img src="fig1.png" data-src="fig1.png" class="lazyload" alt="" >&lt;/a>
&lt;figcaption style="text-align:left">
Latent failure of cloning
&lt;/figcaption>
&lt;/figure>
&lt;h2 id="debugging-execution-and-design-errors">
&lt;a href="#debugging-execution-and-design-errors" class="anchor">
&lt;svg class="icon" aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16">
&lt;path fill-rule="evenodd"
d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z">
&lt;/path>
&lt;/svg>
&lt;/a>
Debugging execution and design errors
&lt;/h2>
&lt;p>So what do you do when your cloning has failed? The typical advice is:&lt;/p>
&lt;ol>
&lt;li>Do it again (and add a positive control this time, you rookie)&lt;/li>
&lt;li>Order new reagents or use a different kit (because clearly, it&amp;rsquo;s the reagents&amp;rsquo; fault, not yours)&lt;/li>
&lt;li>Check your fragments and regenerate your input sample (just in case)&lt;/li>
&lt;li>&lt;a href="https://bakingbiologist.wordpress.com/2012/10/05/starting-grad-school-trust-nobody/">Trust nobody&lt;/a> (not even yourself)&lt;/li>
&lt;/ol>
&lt;p>With experience, you become better at catching execution errors, and you can develop intuitions which can help you narrow down what follow up conditions to try.&lt;/p>
&lt;p>But even if you execute protocols perfectly, your cloning can still fail. Why? Because sometimes, the very DNA you&amp;rsquo;re trying to clone is the problem.&lt;/p>
&lt;p>Cloning involves introducing new DNA sequences into a host organism. But the protein you&amp;rsquo;re trying to clone might be toxic to the host, or the DNA might contain hidden elements that produce unexpected, harmful products (called &lt;a href="https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0136396">cryptic genetic elements&lt;/a>), or the plasmid may contain sequences such as repeats that make it unstable. Even for hosts like &lt;em>E. coli&lt;/em>, we can&amp;rsquo;t always predict whether it will tolerate a particular DNA sequence.&lt;/p>
&lt;p>In lieu of perfect predictability, scientists have come up with many &amp;ldquo;&lt;a href="https://pubmed.ncbi.nlm.nih.gov/16472168/">rules&lt;/a>&amp;rdquo; for designing plasmids and DNA fragments. Use tightly regulated expression systems! Reduce repetitive regions! Use efficient overhangs! For beginners to cloning, understanding why these rules exist by unintentionally violating them is almost a rite of passage. I know it was for me.&lt;/p>
&lt;p>The problem? Not all, but many rules are context- and host-dependent and only become apparent after years of experience. Current plasmid design systems (Benchling, SnapGene) incorporate some basic rule-checking, but they can&amp;rsquo;t account for the diversity of sequences that scientists want to clone. Instead, the state of the art in plasmid design error-checking is to copy and paste your plasmid into various web servers to predict things about your plasmid, and to have your most experienced cloning guru look over your design—bless them.&lt;/p>
&lt;figure>
&lt;a data-fancybox="" href="fig2.png" data-caption="Each failure state could have been caused by one of many errors. Note this diagram does not aim to be comprehensive.">
&lt;img src="fig2.png" data-src="fig2.png" class="lazyload" alt="" >&lt;/a>
&lt;figcaption style="text-align:left">
Each failure state could have been caused by one of many errors. Note this diagram does not aim to be comprehensive.
&lt;/figcaption>
&lt;/figure>
&lt;h2 id="the-future-of-cloning">
&lt;a href="#the-future-of-cloning" class="anchor">
&lt;svg class="icon" aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16">
&lt;path fill-rule="evenodd"
d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z">
&lt;/path>
&lt;/svg>
&lt;/a>
The future of cloning
&lt;/h2>
&lt;p>Faced with these challenges, some biologists are turning to alternative methods. &amp;ldquo;&lt;a href="https://genomebiology.biomedcentral.com/articles/10.1186/s13059-015-0653-x">Cloning-free&lt;/a>&amp;rdquo; techniques, outsourcing to companies (Genscript, VectorBuilder, Twist), and &amp;ldquo;&lt;a href="https://fnkprddata.blob.core.windows.net/domestic/data/datasheet/ORC/MS0011-A.pdf">cell-free cloning&lt;/a>&amp;rdquo; are all attempts to avoid the dreaded cloning.&lt;/p>
&lt;p>But in many cases, cloning simply must be done. What can be done to make it less potentially painful? Here are a few ideas:&lt;/p>
&lt;ol>
&lt;li>&lt;strong>Reducing execution variance&lt;/strong>: Ideally, you would never have to question whether something went wrong due to human execution error. One development in this vein is &lt;a href="https://telesisbio.com/products/bioxp-system/bioxp-3250-system/">benchtop cloning automation&lt;/a>, although at $25,000 I’m not sure how appealing it is to labs. For the price of two of those you could hire a human cloning machine—a grad student.&lt;/li>
&lt;li>&lt;strong>Predictive modeling&lt;/strong>: We need better models to predict how DNA sequences will behave in host organisms. Many already exist, for example &lt;a href="https://www.nature.com/articles/s41467-022-32829-5">transcription&lt;/a> and &lt;a href="https://pubmed.ncbi.nlm.nih.gov/21601672/">translation&lt;/a> prediction in &lt;em>E. coli&lt;/em>, and we need to use them more. This could help us identify potential issues before we even start cloning.&lt;/li>
&lt;li>&lt;strong>Better design tools&lt;/strong>: DNA design software could incorporate more sophisticated rules and predictive models, helping scientists create sequences that are more likely to work. Large language models still lag quite a bit behind humans on answering questions on cloning related tasks (&lt;a href="https://arxiv.org/abs/2407.10362">LAB-bench&lt;/a>), but I wouldn’t be surprised if that changes soon.&lt;/li>
&lt;li>&lt;strong>Interpretable intermediate states&lt;/strong>: If we could easily check the correctness of each step, debugging cycles could be shortened.&lt;/li>
&lt;/ol>
&lt;p>Because of how common it is, I think it is easy to think of cloning as being a procedure with certain success if you don’t mess up (and there are many ways to mess up). But cloning is in part an experiment to see whether a certain host organism will tolerate a certain plasmid.&lt;/p>
&lt;p>And hey, if all else fails, there&amp;rsquo;s always that contract with a demon to consider.&lt;/p>
&lt;h2 id="appendix">
&lt;a href="#appendix" class="anchor">
&lt;svg class="icon" aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16">
&lt;path fill-rule="evenodd"
d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z">
&lt;/path>
&lt;/svg>
&lt;/a>
Appendix
&lt;/h2>
&lt;p>Some other cloning-related odds and ends that may be of interest:&lt;/p>
&lt;ul>
&lt;li>
&lt;p>Your clonal colonies may not actually be clonal. See “&lt;a href="https://www.nature.com/articles/s41598-022-14598-9">High rates of plasmid cotransformation in E. coli overturn the clonality myth and reveal colony development&lt;/a>”&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Of 301 plasmids tested in E. coli ~20% caused some level of growth defect (&lt;a href="https://www.nature.com/articles/s41467-024-50639-9">Radde et al. 2024&lt;/a>)&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Analysis of expression of 29 glycolytic proteins in yeast found they can be overexpressed until they form 15% of the total proteins in a yeast cell (&lt;a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6086662/">Eguchi et al. 2018&lt;/a>)&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Sam Rodriques on why cloning is hard to automate (&lt;a href="https://twitter.com/SGRodriques/status/1785855017137975801">tweet&lt;/a>):&lt;/p>
&lt;blockquote>
&lt;p>E.g. in cloning, everyone has a design workflow they prefer, but any individual plasmid will usually require some modification in the design process. E.g. maybe the sequence isn’t available on Addgene, maybe the restriction site you want to use is methylated, maybe there are repeats, etc. You can write a script to automate design of any individual plasmid (or maybe any individual backbone), but the same script only rarely works across many plasmids. Everything is an edge case.&lt;/p>
&lt;/blockquote>
&lt;/li>
&lt;li>
&lt;p>DNA quantification is different from instrument to instrument, as much as &lt;a href="https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0305650">several fold different&lt;/a>. Thanks to Niko McCarty for surfacing this paper.&lt;/p>
&lt;figure>
&lt;a data-fancybox="" href="fig3.png" data-caption="Qubit is quite different compared to DeNovix and NanoDrop">
&lt;img src="fig3.png" data-src="fig3.png" class="lazyload" alt="" >&lt;/a>
&lt;figcaption style="text-align:left">
Qubit is quite different compared to DeNovix and NanoDrop
&lt;/figcaption>
&lt;/figure>
&lt;/li>
&lt;/ul>
&lt;h2 id="acknowledgements">
&lt;a href="#acknowledgements" class="anchor">
&lt;svg class="icon" aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16">
&lt;path fill-rule="evenodd"
d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z">
&lt;/path>
&lt;/svg>
&lt;/a>
Acknowledgements
&lt;/h2>
&lt;p>Thank you to Laura Quinto and Chase Armer for looking over drafts of this piece and providing feedback.&lt;/p>
&lt;h2 id="other-similar-essays-i-enjoyed">
&lt;a href="#other-similar-essays-i-enjoyed" class="anchor">
&lt;svg class="icon" aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16">
&lt;path fill-rule="evenodd"
d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z">
&lt;/path>
&lt;/svg>
&lt;/a>
Other similar essays I enjoyed
&lt;/h2>
&lt;ul>
&lt;li>&lt;a href="https://twitter.com/koeng101/status/1793123441882902798">Too much Tacit&lt;/a> (Keoni Gandall)&lt;/li>
&lt;li>&lt;a href="https://ai.stanford.edu/~zayd/why-is-machine-learning-hard.html">Why is machine learning &amp;lsquo;hard&amp;rsquo;?&lt;/a> (S. Zayd Enam)&lt;/li>
&lt;/ul></description></item><item><title>Leaf color change in 10,950 iNaturalist observations</title><link>https://etowahadams.github.io/post/2020-01-09-maple-red-leaf/</link><pubDate>Thu, 09 Jan 2020 21:19:07 -0500</pubDate><guid>https://etowahadams.github.io/post/2020-01-09-maple-red-leaf/</guid><description>
&lt;figure>
&lt;a data-fancybox="" href="process.jpg" data-caption="Process overview. Skip to process explanation">
&lt;img src="process.jpg" data-src="process.jpg" class="lazyload" alt="" >&lt;/a>
&lt;figcaption style="text-align:left">
Process overview. &lt;a href="#process">Skip to process explanation&lt;/a>
&lt;/figcaption>
&lt;/figure>
&lt;p>One of the unexpected consequences of attending college in Connecticut has been experiencing autumn twice a year. I watch the trees of New Haven&lt;sup id="fnref:1">&lt;a href="#fn:1" class="footnote-ref" role="doc-noteref">1&lt;/a>&lt;/sup> change color during late October and early November, then return home in Georgia for fall break and watch the leaves change color again.&lt;/p>
&lt;p>I understood the basic principle behind my double-dipping of fall. In late October, Connecticut is colder and receives less daylight hours than my home in Georgia, triggering trees stop making green chlorophyll and allowing the yellows, oranges, and reds of the other pigments (like xanthophylls, carotenoids, and anthocyanins) to become visible earlier. However, I began to wonder when autumn came to other parts of North America, and the rate that it moved. I have seen fall color forecasts. But what would it look like actually to observe leaf color change across the whole continent? I decided to tackle this question over my winter break.&lt;/p>
&lt;p>Having been a contributor for several years now, I turned to &lt;a href="https://www.inaturalist.org/">iNatrualist&lt;/a> for answers. For the uninitiated, iNaturalist is a website where users can submit and identify observations of any taxa of life: a social media for naturalists in a sense. I had three qualifications choosing a tree species. It had to have a drastic fall color change, a large range, and many observations. After considering Sugar Maple, (&lt;em>Acer saccharum&lt;/em>), Sassafras (&lt;em>Sassafras albidum&lt;/em>), Trembling Aspen (&lt;em>Populus tremuloides&lt;/em>), among other trees, I finally decided on &lt;a href="https://www.inaturalist.org/taxa/48098-Acer-rubrum">Red Maple&lt;/a> (&lt;em>Acer rubrum&lt;/em>), which had the highest observation count.&lt;/p>
&lt;h2 id="results">
&lt;a href="#results" class="anchor">
&lt;svg class="icon" aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16">
&lt;path fill-rule="evenodd"
d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z">
&lt;/path>
&lt;/svg>
&lt;/a>
Results
&lt;/h2>
&lt;figure>
&lt;video autoplay loop width="100%" preload="auto">
&lt;source src="2019.mp4" type="video/mp4">
&lt;/video>
&lt;figcaption style="text-align:left">
&lt;strong>Figure 1:&lt;/strong> 2019 research grade observations of &lt;em>A. rubrum&lt;/em> with leaves. The color of each marker corresponds to the dominant color of the leaves in the respective observation. Each marker disappears 10 days (frames) after it first appears. At the end of April, observations get green as trees “green up,” and fall colors start appearing at the start of October and spread south.
&lt;/figcaption>
&lt;/figure>
&lt;figure>
&lt;a data-fancybox="" href="observation-count.jpg" data-caption="Figure 2 (left): Number of observations of A. rubrum versus week of the year. At the 17th week (around the 4th week of April) there is a sharp spike in the number of observations. I expect this to be when the first leaves first start coming out and everyone is submitting their first A. rubrum observation of the year. Figure 3 (right): Number of observations with leaves versus week of the year. As expected, there is not much difference between figure 2 and figure 3. People usually submit observations with leaves in them. However, notice that in weeks 1-16, there less observations compared to in figure 2, suggesting that the spike of observations at week 17 is because of the emergence of leaves. Still, the peak is remarkably high.">
&lt;img src="observation-count.jpg" data-src="observation-count.jpg" class="lazyload" alt="" >&lt;/a>
&lt;figcaption style="text-align:left">
&lt;strong>Figure 2 (left)&lt;/strong>: Number of observations of A. rubrum versus week of the year. At the 17th week (around the 4th week of April) there is a sharp spike in the number of observations. I expect this to be when the first leaves first start coming out and everyone is submitting their first &lt;em>A. rubrum&lt;/em> observation of the year. &lt;strong>Figure 3 (right)&lt;/strong>: Number of observations with leaves versus week of the year. As expected, there is not much difference between figure 2 and figure 3. People usually submit observations with leaves in them. However, notice that in weeks 1-16, there less observations compared to in figure 2, suggesting that the spike of observations at week 17 is because of the emergence of leaves. Still, the peak is remarkably high.
&lt;/figcaption>
&lt;/figure>
&lt;figure>
&lt;video autoplay loop width="100%" preload="auto">
&lt;source src="allyears.mp4" type="video/mp4">
&lt;/video>
&lt;figcaption style="text-align:left">
&lt;strong>Figure 4&lt;/strong>: 2016, 2017, 2018, and 2019 research grade observations of &lt;em>A. rubrum&lt;/em> with leaves. 2015 omitted so that a nice square could be made
&lt;/figcaption>
&lt;/figure>
&lt;figure>
&lt;a data-fancybox="" href="fall-colors.jpg" data-caption="Figure 5: Number of observations with “fall” colors in each week of the year for 2015-2019. “Fall” color was defined in an HSV color model as colors with a hue (0-360) &amp;gt; 300 or &amp;lt; 60, a saturation (0-1) &amp;gt; 0.09, and a value (0-255) &amp;gt; 150. Peaks are present at week 17, and weeks 41-44. Week 17 is overrepresented because of the number of total observations in that week, but early leaves can be reddish. Interestingly the 2018 fall colors appear to be about two weeks later as a whole compared to 2019. The late 2018 fall was observed by others, and was attributed to higher than average daily low temperatures.">
&lt;img src="fall-colors.jpg" data-src="fall-colors.jpg" class="lazyload" alt="" >&lt;/a>
&lt;figcaption style="text-align:left">
&lt;strong>Figure 5&lt;/strong>: Number of observations with “fall” colors in each week of the year for 2015-2019. “Fall” color was defined in an HSV color model as colors with a hue (0-360) &amp;gt; 300 or &amp;lt; 60, a saturation (0-1) &amp;gt; 0.09, and a value (0-255) &amp;gt; 150. Peaks are present at week 17, and weeks 41-44. Week 17 is overrepresented because of the number of total observations in that week, but early leaves can be reddish. Interestingly the 2018 fall colors appear to be about two weeks later as a whole compared to 2019. The late 2018 fall was observed by &lt;a href="https://weather.com/science/weather-explainers/news/2018-10-03-why-foliage-fall-color-is-late-warm-east">others&lt;/a>, and was attributed to higher than average daily low temperatures.
&lt;/figcaption>
&lt;/figure>
&lt;h2 id="process">
&lt;a href="#process" class="anchor">
&lt;svg class="icon" aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16">
&lt;path fill-rule="evenodd"
d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z">
&lt;/path>
&lt;/svg>
&lt;/a>
Process
&lt;/h2>
&lt;p>I painstakingly looked through the images of all 10,000+ observations and wrote down each the color of the leaves in each observation.&lt;/p>
&lt;p>Just kidding.&lt;/p>
&lt;h3 id="leaf-detection">
&lt;a href="#leaf-detection" class="anchor">
&lt;svg class="icon" aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16">
&lt;path fill-rule="evenodd"
d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z">
&lt;/path>
&lt;/svg>
&lt;/a>
Leaf Detection
&lt;/h3>
&lt;p>An observation’s images could contain branches, buds, bark, roots, seeds, and any number of other features to help with identification. So, I knew I had to detect if there was a leaf in in the image, and where the leaf was in the image. In other words, I was dealing with object detection. I chose a deep learning approach, You Look Only Once (YOLO), for object detection because of its speed and good documentation.&lt;/p>
&lt;p>Using the &lt;a href="https://api.inaturalist.org/v1/docs/">iNatrualist API&lt;/a>, I downloaded the images from every 10th page of research grade &lt;em>A. rubrum&lt;/em> observations. I created a training set by labeling the leaves in 800 images using LabelImg and trained the model for 3500 batches (around 16 hours on my computer). In hindsight, I could have had even better accuracy if I had created additional classes for other features like branches and seeds, but overall, I am pleased with the performance of the model. There are several instances where it identified very small leaves, getting more sky than leaf, resulting several blue to white dominant color however. See the object detector on &lt;a href="https://github.com/etowahs/leaf-detector">Github&lt;/a>.&lt;/p>
&lt;figure>
&lt;a data-fancybox="" href="leaf-detection.jpg" data-caption="Figure 6: Leaves detected by YOLOv3 object detector trained on 800 labeled images">
&lt;img src="leaf-detection.jpg" data-src="leaf-detection.jpg" class="lazyload" alt="" >&lt;/a>
&lt;figcaption style="text-align:left">
&lt;strong>Figure 6&lt;/strong>: Leaves detected by YOLOv3 object detector trained on 800 labeled images
&lt;/figcaption>
&lt;/figure>
&lt;h3 id="leaf-color">
&lt;a href="#leaf-color" class="anchor">
&lt;svg class="icon" aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16">
&lt;path fill-rule="evenodd"
d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z">
&lt;/path>
&lt;/svg>
&lt;/a>
Leaf Color
&lt;/h3>
&lt;p>Once I knew where the leaf was, I expected getting the leaf color to be easy, but it required more experimentation than I expected. At first, I tried to get the color of the leaf without doing any additional manipulation to the leaf sub-image. I used k-means clustering to get the dominant color of the image. I was surprised by how well k = 3 performed, but I thought I could get an even better color if I extracted the foreground.&lt;/p>
&lt;figure>
&lt;a data-fancybox="" href="domcolor.jpg" data-caption="Figure 7: Dominant color using k-means clustering.">
&lt;img src="domcolor.jpg" data-src="domcolor.jpg" class="lazyload" alt="" >&lt;/a>
&lt;figcaption style="text-align:left">
&lt;strong>Figure 7&lt;/strong>: Dominant color using k-means clustering.
&lt;/figcaption>
&lt;/figure>
&lt;p>I tried a variety of methods, including creating masks from the largest contour provided by canny edge detection and adaptive thresholding, but with limited success. Eventually I stumbled upon the grabcut algorithm, which performed miles better than anything I had come up with.&lt;/p>
&lt;figure>
&lt;a data-fancybox="" href="adaptive-thresholding2.jpg" data-caption="Figure 8: Foreground extraction using mask created with the largest contour found using adaptive thresholding. Not terrible, but also not good.">
&lt;img src="adaptive-thresholding2.jpg" data-src="adaptive-thresholding2.jpg" class="lazyload" alt="" >&lt;/a>
&lt;figcaption style="text-align:left">
&lt;strong>Figure 8&lt;/strong>: Foreground extraction using mask created with the largest contour found using adaptive thresholding. Not terrible, but also not good.
&lt;/figcaption>
&lt;/figure>
&lt;figure>
&lt;a data-fancybox="" href="grabcut.jpg" data-caption="Figure 9: Foreground extraction using grabcut, followed by k-means clustering (k = 2) of the foreground. Much better.">
&lt;img src="grabcut.jpg" data-src="grabcut.jpg" class="lazyload" alt="" >&lt;/a>
&lt;figcaption style="text-align:left">
&lt;strong>Figure 9&lt;/strong>: Foreground extraction using grabcut, followed by k-means clustering (k = 2) of the foreground. Much better.
&lt;/figcaption>
&lt;/figure>
&lt;p>Grabcut worked well for leaves with defined edges, but for leaves with less defined leaf edges, sometimes it would cut out the entire foreground, which in case I would get the dominant color of the entire leaf sub-image. When an observation had multiple leaves, I got the dominant color (k = 2) of the dominant colors of each of the leaves. If I were to do it over, I would have combined the extracted leaf foregrounds into the same array, and taken the dominant color of that.&lt;/p>
&lt;p>Once I got the main image processing pipeline set up, I ran it on the images with leaves in them for all the observations of &lt;em>A. rubrum&lt;/em> between 2015-2019. See it on &lt;a href="https://github.com/etowahs/leaf-colors">Github&lt;/a>.&lt;/p>
&lt;h2 id="creating-the-graphics">
&lt;a href="#creating-the-graphics" class="anchor">
&lt;svg class="icon" aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16">
&lt;path fill-rule="evenodd"
d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z">
&lt;/path>
&lt;/svg>
&lt;/a>
Creating the Graphics
&lt;/h2>
&lt;p>I initially created a map using leaflet.js but animating the markers was not smooth enough for my liking. Instead, for every day in each year I generated an SVG image. These images were combined into a gif, using Imagemagick, and then converted into a mp4 using ffmpeg. For a future project, I would like to try something with CSS sprite sheet animation, d3.js, or maybe even three.js, but for a long animation like this one, I think the gif was appropriate and is very sharable.&lt;/p>
&lt;h2 id="concluding-thoughts">
&lt;a href="#concluding-thoughts" class="anchor">
&lt;svg class="icon" aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16">
&lt;path fill-rule="evenodd"
d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z">
&lt;/path>
&lt;/svg>
&lt;/a>
Concluding Thoughts
&lt;/h2>
&lt;p>I found it fascinating to see leaf colors change across eastern North America. Observations are increasing every year so this type of visualization will only get better, although certainly they will be skewed towards certain geographic areas and time periods. Users tend to submit observations when they notice something different, so data mostly comes from periods of transitions. I was happy to see that the &lt;a href="https://www.washingtonpost.com/weather/2018/10/19/weve-never-seen-anything-like-this-fall-foliage-still-missing-action-across-mid-atlantic/">late timing of fall colors of 2018&lt;/a> was reflected in figure 5.&lt;/p>
&lt;div class="footnotes" role="doc-endnotes">
&lt;hr>
&lt;ol>
&lt;li id="fn:1">
&lt;p>See this cool &lt;a href="https://uri.yale.edu/maps/street-tree-inventory-map">map&lt;/a> of New Haven trees by Yale Urban Resource Initiative&amp;#160;&lt;a href="#fnref:1" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;/ol>
&lt;/div></description></item></channel></rss>